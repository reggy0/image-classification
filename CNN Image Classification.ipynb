{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/reggy0/image-classification/blob/main/CNN%20Image%20Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9l_PvRWFCZ2"
      },
      "source": [
        "#### Building the CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gNfSxqbPFCZ7",
        "outputId": "3d619ea0-cb80-43e5-88d4-42e7c83ea6e5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ]
        }
      ],
      "source": [
        "#importing the libraries\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Convolution2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1OuHJCX7FCaP",
        "outputId": "26889547-0dfb-446c-891a-f6b83e5a5747"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0806 18:29:45.816555 4419089856 deprecation_wrapper.py:119] From /anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "classifier= Sequential() # Initialise the CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbPjouWAFCaT"
      },
      "source": [
        "#### Steps\n",
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vk7j91GsFCaX",
        "outputId": "19918e2d-b1f6-49cb-c878-cd1db1963e78"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0806 18:29:45.852214 4419089856 deprecation_wrapper.py:119] From /anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0806 18:29:45.860280 4419089856 deprecation_wrapper.py:119] From /anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Ist step of Convoltional layer to get feature maps using feature detector\n",
        "classifier.add(Convolution2D(filters=32, # output feature maps\n",
        "                             kernel_size=(3,3), # matrix size for feature detector\n",
        "                             input_shape=(64, 64, 3), # input image shape, 3 is for rgb coloured image with 128*128 px\n",
        "                             kernel_initializer='he_uniform', # weights distriution\n",
        "                             activation='relu')) # activation function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G5hRbgwyFCad",
        "outputId": "4c54f99c-4d54-431d-a380-32bade1e4c67"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0806 18:29:45.901446 4419089856 deprecation_wrapper.py:119] From /anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 2nd Pooling layer\n",
        "classifier.add(MaxPooling2D(pool_size=(2,2)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "We6w6_kbFCai"
      },
      "outputs": [],
      "source": [
        "#2nd convolutional and pooling layer.\n",
        "classifier.add(Convolution2D(filters=32,\n",
        "                             kernel_size=(3,3), \n",
        "                             kernel_initializer='he_uniform', \n",
        "                             activation='relu'))\n",
        "classifier.add(MaxPooling2D(pool_size=(2,2)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQCDUd8bFCao"
      },
      "source": [
        "in case we dont do do convolutional and pooiling and directly flatten our input image pixel and pass it , out network wont be able to find the relations between each pixels and will treat each pixel indiviually."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ER8dN_pFCat"
      },
      "outputs": [],
      "source": [
        "# Step 3 - Flattening\n",
        "classifier.add(Flatten())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "DF7h6X5TFCa5",
        "outputId": "2c925ef6-c11b-44aa-c628-34f07eada532"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0806 18:29:46.016646 4419089856 deprecation_wrapper.py:119] From /anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0806 18:29:46.054260 4419089856 deprecation_wrapper.py:119] From /anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0806 18:29:46.063058 4419089856 deprecation.py:323] From /anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ]
        }
      ],
      "source": [
        "#Step 4 full connection in which input we have from flattening\n",
        "\n",
        "classifier.add(Dense(units=128,kernel_initializer='glorot_uniform', activation='relu')) \n",
        "#step 5 output layer\n",
        "classifier.add(Dense(units=1,kernel_initializer='glorot_uniform',activation='sigmoid'))\n",
        "# Compiling the CNN\n",
        "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeQ2cqCjFCa_"
      },
      "source": [
        "#### Fitting the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRotx6fxFCbC"
      },
      "source": [
        "In this we first need to do image augmentation using kera image preprocessing modules. It is necessary to to avoid the overfitting when we have less data to train which leat to high training accuracy and low testing accuracy.\n",
        "\n",
        "In this we will make different batches of sub samples , in each batch it will have random transformations like rotating, shifting and flipping which will add diversity to data and being random our model wont get same image to get trained on.\n",
        "\n",
        "This will help us in high performance with no overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PDv_EbveFCbH"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PgIEzBUcFCbL"
      },
      "outputs": [],
      "source": [
        "#applying all the transformation we want to apply to training data set\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zyHQiQpJFCbQ"
      },
      "outputs": [],
      "source": [
        "#Rescling the test data set images to use for validation.\n",
        "test_datagen= ImageDataGenerator(rescale=1./255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "niaOthLxFCbT",
        "outputId": "8aa60834-2be2-4ef1-96f2-d22a14051050"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 8000 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "#Getting My training data ready for validation, so it will read all the data with the px size we gave.\n",
        "\n",
        "training_set= train_datagen.flow_from_directory(directory= 'dataset/training_set',\n",
        "                                               target_size=(64,64), # As we choose 64*64 for our convolution model\n",
        "                                               batch_size=50,\n",
        "                                               class_mode='binary' # for 2 class binary \n",
        "                                               )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3jIkWsw9FCbY",
        "outputId": "45468b14-76d2-4f35-9bbc-5e1e30759575"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "#Getting My test data ready for validation, so it will read all the data with the px size we gave.\n",
        "\n",
        "test_set= test_datagen.flow_from_directory(directory= 'dataset/test_set',\n",
        "                                               target_size=(64,64), # As we choose 64*64 for our convolution model\n",
        "                                               batch_size=50,\n",
        "                                               class_mode='binary' # for 2 class binary\n",
        "                                          )\n",
        "                                           "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bk3YjqBNFCbc"
      },
      "outputs": [],
      "source": [
        "classifier.fit_generator(training_set, #training data to fit\n",
        "                        steps_per_epoch=8000, # Data in training set\n",
        "                        epochs=5, # No of epochs to run\n",
        "                        validation_data=test_set, # Test or validation set\n",
        "                        validation_steps=2000 # no of data point for validation\n",
        "                        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rjqROpFLFCbf"
      },
      "outputs": [],
      "source": [
        "# Part 3 - Making new predictions\n",
        "\n",
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "test_image = image.load_img('dataset/single_prediction/cat_or_dog_1.jpg', target_size = (64, 64))\n",
        "# Loading the image and converting the pixels into array whcih will be used as input to predict.\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis = 0)\n",
        "result = classifier.predict(test_image)\n",
        "training_set.class_indices\n",
        "if result[0][0] == 1:\n",
        "    prediction = 'dog'\n",
        "else:\n",
        "    prediction = 'cat'"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "CNN Image Classification.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}